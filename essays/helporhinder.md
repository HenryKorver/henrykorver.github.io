---
layout: essay
type: essay
title: How Does AI Help or Hinder Learning outcomes?
date: 2025-12-16
published: true
labels:
---

## I. Introduction

Generative AI has improved during my time as a student. LLMs can complete difficult tasks based on vague instructions. Diffusion models can generate images or videos that look very realistic. A decade ago, none of these tools were even remotely practical. Given the rapid development in the generative AI space, universities have had to decide what role AI plays in learning.

## II. Personal Experience with AI

### Experience WODs
I tried to avoid using AI for these experiences, since there was a YouTube tutorial to follow if I was unable to solve it on my own.

### In-class Practice WODs
At the start of the semester, I was stressed about doing as well as possible on the in class WODs, so I would use AI aggressively to do these as quickly as possible. After the third practice WOD I began to use these as an opportunity to learn about how my classmates approached the WODs and treated the assignments similarly to the experience WODs.

### In-class WODs
I definitely noticed falling back into AI use whenever there was some added time pressure. I don't think there was 

### Essays
I approached the essay in one of two ways. The first way I approached the essays was to type an outline myself, then use an LLM to turn it into a standard essay format. The second way, I fed the LLM instructions and asked it to generate the outline. From there, I filled in the details, gave examples, and tweaked the word choice in places to match my tone better. Both methods robbed my work of some of its authenticity and in some ways were not representative of my true voice or thinking. The upside was that the AI-assisted essays were completed more quickly and with fewer mistakes. 

### Final Project
In the final project, I used AI primarily to understand the code of my peers. This was something super useful because it allowed us to reduce communication overhead substantially. I also wrote some typescript to handle API keys for ChatGPT automoderation of the user-generated content of our final project (RateMyTools).

### Learning a Concept / Tutorial
I think the tutorial aspect of AI can be helpful from time to time, but it's too easy to just sit back idly, while the LLM does something you only half-understand. It's better served as an interlocuter, giving you a back-and-forth dialogue, and compartmentalizing a technical task into manageable chunks. Even this has issues, as most AI chatbots want to do everything for you.

### Answering a Question in Class or in Discord
I looked up a couple of questions in class questions on various chatbots, but they gave answers that generally exceeded the scope of the class. This makes sense as the RLHF fine tuning is on generic answer and response stuff for the broadest application, and is not course specific. It would be interesting to see if you could take a 

### Asking or Answering a Smart-Question
I think that this is a pretty good use case for AI currently. An interpreter between two people who speak the same language may seem unnecessarily circuitous, but within the context of smart-questions, there are often technical gaps in vocabulary between the asker and the answerer. AI can help the asker provide a more detailed, consistent question, while giving the answerer a more general, heuristic-based answer (rather than just narrow technical details).

### Coding Example
Every AI I tried was pretty fantastic at generating template code. It was even pretty good at doing this for coding tasks within relatively niche libraries and frameworks.

### Explaining Code
I would say it was pretty good at this for the most part, and can even help you understand some pretty complicated code, but I'm not sure understanding the natural language explanation of the code is always easier than just looking at the code yourself. I tried asking it to provide some of its explanations visually, and it performed pretty humorously in its attempts to produce flowcharts and sequence diagrams.

### Writing Code
For the final project, I fed AI some psuedocde and let it generate the approrpiately formated typescript. Not doing this, and just giving it a specific task often lead to code that is intractable and confusing (to me in particular).

### Documenting Code

If I was too lazy I would have AI do this as I figured barely anyone looks at documentation, but I think generally I did a better job than it.

### Quality Assurance

AI was pretty good at spotting stupid errors like a variable name typo or something similar. Having Copilot autocomplete enabled was another good quality assurance measure.

### Other Uses in ICS 314
That covers it.

## III. Impact on Learning and Understanding

As a tutor, I don't think that any of the cutting-edge models are fantastic at tutoring out of the box. It knows the material and can give a good explanation. It does not, however, know when to withhold information and let you think for yourself. If you ask it to give you some resistance, it can do a little bit better, but will often default back to characteristic sychophancy. Maybe if you fine tuned an educational model on student exam perfomance you could circumvent this issue?

## IV. Practical Applications

I haven't explored AI as extensively outside as I have inside it. My general thoughts are that using it would make me more objective-focused and less process-focused, allowing me to complete unfinished projects, but to quality standards I might be unhappy with.

## V. Challenges and Opportunities

The primary challenge I encountered with the LLMs was their urge to please. LLMs are designed to be helpful, not educational. They provide the solution immediately rather than guiding you through the problem-solving process.

On the other side of the coin, this challenge provides a pretty robust opportunity. If some models are tweaked to push back, and not just spoon-feed users answers, they could become fantastic personal tutors. Prompting them correctly can often help achieve this outcome, albeit imperfectly.

## VI. Comparative Analysis

The traditional approach, which I stuck to for the Experience WODs (using YouTube tutorials or documentation), helped me retain the syntax better. When I had to type out the code or debug it manually, I internalized the syntax and logic. The downside is the time investment; getting stuck on a syntax error for half an hour is not an efficient use of time.

The AI approach was faster to get started, but resulted in a greater accumulation of technical debt. I also don't really know what to say about the philosophical questions surrounding ownership of "AI-assisted" content. The 

## VII. Future Considerations

LLMs are an exceptional tool and are likely to continue improving performance on benchmarks. 

## VIII. Conclusion

Although AI may have lessened my web development learning experience, I did learn a great deal about LLMs and generative AI in general. 20 years from now, I'll know which topic was more important.
